Eurographics/ IEEE-VGTC Symposium on Visualization 2009
H.-C. Hege, I. Hotz, and T. Munzner
(Guest Editors)
Volume 28 (2009), Number 3
Context-aware Volume Modeling of Skeletal Muscles
Zhicheng Yan†1 Wei Chen‡1 Aidong Lu§2 David S. Ebert¶3
1State Key Lab of CAD&CG, Zhejiang University, China
2University of North Carolina at Charlotte, USA
3Purdue University, USA
Abstract
This paper presents an interactive volume modeling method that constructs skeletal muscles from an existing
volumetric dataset. Our approach provides users with an intuitive modeling interface and produces compelling
results that conform to the characteristic anatomy in the input volume. The algorithmic core of our method is an
intuitive anatomy classification approach, suited to accommodate spatial constraints on the muscle volume. The
presented work is useful in illustrative visualization, volumetric information fusion and volume illustration that
involve muscle modeling, where the spatial context should be faithfully preserved.
Categories and Subject Descriptors (according to ACM CCS): I.3.5 [Computer Graphics]: Curve, surface, solid, and
object representations—
1. Introduction
Modeling and illustrating muscle volumes are of great inter-
ests in many applications, such as medical illustration, treat-
ment planning for musculoskeletal disorder, and anatomical
dynamics simulation [STS90,SPCM97,BTS?05]. In this pa-
per, we address a challenging problem of interactive volume
modeling of skeletal muscles, which is to construct outlier
shapes and internal fibrous structures of skeletal muscles in
the volumetric representation. The challenge is to achieve
the quality currently attainable from three-dimensional mod-
eling systems with simple yet effective interactions.
Existing geometric modeling approaches [SPCM97,
KHS01] exploit the anatomical structures provided by an un-
derlying skeleton to construct reliable muscle geometry in
the three-dimensional space. They will require a conversion
between geometric models and volumetric representations
if real-world anatomy is used. In the meantime, many solu-
tions [BTS?05, TSB?05] build musculoskeletal systems by
taking biomechanics into account. They could be slow and
† yanzhicheng@cad.zju.edu.cn
‡ Corresponding author. chenwei@cad.zju.edu.cn
§ aidong.lu@uncc.edu
¶ ebertd@purdue.edu
labor intensive, especially when there is complex anatomy
around the muscle volume.
Volume modeling approaches that work directly with
measured volumetric datasets can be very sophisticated
in terms of efficiency and fidelity. Many intuitive inter-
faces [SS04, CSC06, BGKG06, CCI?07] have been intro-
duced to reduce user interactions for general volume data to
a great extent, yet without sacrificing the rendering quality.
However, this trend has not happened in muscle modeling,
mainly because modeling muscle volume requires a correct
anatomical context. A better user interface is needed to accu-
rately specify the relationships between underlying muscle
and surrounding anatomy.
Specifically, there are two important properties required
for a muscle volume modeling system. On one hand, the
modeled muscle should conform to its anatomy context, e.g.,
not intersecting with bones and preserving the anatomical re-
lationships. On the other hand, the user interactions should
be operated on a simple form (two-dimensional interface),
which provides great convenience to the non-professional
modeling users such as medical illustrators.
In this paper, we present a novel volume modeling system
for designing and editing skeletal muscles based on an input
volume. Our focus is not the accuracy and performance of
the shape modeling that have been extensively studied. In-
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
Published by Blackwell Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and
350 Main Street, Malden, MA 02148, USA.
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
stead, we are seeking an optimal two-dimensional painting
interface that allows users to easily classify an input volume,
and thereby discover the anatomical context useful for mod-
eling. This offers effective simplification of modeling oper-
ations, and it is generally suitable for novices. With our sys-
tem, we demonstrate how users can classify volume dataset
and create illustrative visualization of muscle volume in an
intuitive fashion.
The rest of this paper is organized as follows. We review
related work in Section 2. Section 3 introduces the pipeline.
A novel semi-supervised anatomy classification method is
explained in Section 4. Implementation details are provided
in Section 5. We present results for a variety of examples in
Section 6, and conclude the paper in Section 7.
2. Related Work
Muscle modeling Earlier muscle modeling meth-
ods [KHS01] have concentrated on using geometric
shapes to edit muscle models and generate animations.
For example, the anatomy-based muscle modeling tech-
nique [SPCM97] generates and edits muscle models by
exploiting the relationship between exterior forms and cor-
responding underlying structures. They represent a muscle
with a set of parameters including location, orientation,
general shape and volume, which can be flexibly modified to
account for the deformation and movement of an underlying
articulated skeleton. To achieve a high degree of realism,
we think that the generation of muscle models should
incorporate precise knowledge of anatomy.
In terms of physical reality, data-driven muscle model-
ing methods are inherently superior to geometric model-
ing methods. For instance, three-dimensional finite-element
models of muscle [BTS?05] can improve the representations
of muscles with complex geometry. Meanwhile, real-world
volume datasets can also be employed to construct high-
fidelity muscle models [TSB?05] by taking biomechanics
into account.
Note that these schemes perform well in many bio-
medical applications, although they typically require in-
tensive user interactions and certain anatomy knowledge.
This paper compliments existing methods with an intuitive
anatomy classification interface. All studied muscle simula-
tion and manipulation techniques can be used in our system,
although not explicitly shown in our results.
Context-aware volume modeling Volume modeling is a
fundamental problem in volume visualization [CCI?07]. Ex-
tensive research has been engaged in the segmentation, ma-
nipulation, and deformation of volumetric datasets [MTB03,
CCI?07]. For example, Singh and Silver [SS04] proposed
a method that allowed users to choose geometrical compo-
nents and highlight them to depict the context embedded in a
volume dataset effectively. The feature-aligned volume ma-
nipulation approach [CSC06] provides an interactive volume
deformation interface which effectively enables illustrative
visualization. The VolumeShop system [BG05] makes full
use of volume modeling techniques to create a fully dy-
namic three-dimensional volume illustration user interface.
In [BKW08], an interactive volume editing and painting sys-
tem with an efficient three-dimensional brushing toolkit is
described. Our approach provides an add-on to these exist-
ing methods by enhancing the visual expressiveness with a
modeled muscle volume.
Interactive volume classification A transfer func-
tion [PLB?01] maps data values onto optical properties.
Designing a transfer function is logically identical to the
process of identifying features of interest, namely, volume
classification. However, standard histogram-based transfer
function design can hardly incorporate human intervention
into this pattern-recognition process. There has been a vast
body of medical segmentation methods [FRB07, SWY99,
ZBS01]. By regarding a volume data as a three-dimensional
image, existing image classification and segmentation ap-
proaches [BJ01, NN04, RLC04, FRB07] could be extended
to volume classification. Challenges in this include how to
quickly obtain the user specification and how to supervise
the classification procedure.
Recent work makes great progress to fill the gap between
high-level perception and low-level features by means of
advanced supervised learning techniques. The pioneering
work by Tzeng et al. [TLM05] allows the user to specify
semantic regions on some volume slices and forward this
information to a classifier for high-dimensional classifica-
tion. With an attempt to simplify the user interactions, vol-
ume catcher [ONI05] assumes that the classification bound-
aries form a silhouette in the rendered image. The user only
needs to specify the silhouette in two-dimensional images
to generate a set of seeding points for subsequent three-
dimensional volume classification. The volume cutout ap-
proach [YZNC05] elegantly combines the advantages of the
stroke-based user interface and graphcut based segmenta-
tion algorithms. A recently developed volume coloring ap-
proach [BKW08] works in the three-dimensional domain,
facilitating semi-automatic classification and segmentation
of opaque iso-surfaces. Our approach is different from these
methods in that it is augmented by the visualization results,
and only requires simple point-based specification in two-
dimensional images.
3. Overview
As depicted in Figure 1, our muscle modeling system con-
sists of two stages: volume classification and muscle con-
struction. The input of our approach includes a volume
dataset and its associated transfer function. The user deter-
mines semantically different regions by marking points on
the rendered image. These indications are extended into the
three-dimensional space along the viewing direction, result-
ing in a collection of sampling points. Subsequently, we em-
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
888
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
Rendered image
User    interaction
User  indication
Volume data
Transfer function
User interface of muscle modeling Muscle illustration
Direct volume rendering
Semi-supervisied 
classification
Muscle volume modeling
Labled 2D points
Statistical
 region merging
Volume classificationUnlabled 3D points Labeld 3D points
Figure 1: The conceptual overview of our approach.
ploy a semi-supervised learning algorithm to classify the set
of the sampling points and the marking points in the im-
age plane, and thus label the voxels in which the sampling
points lie. Then, we use a statistical region merging approach
to perform volume classification. The volume classification
can be incrementally enhanced by specifying more marking
points under different viewpoints or transfer functions.
The muscle modeling is performed interactively with a set
of modeling widgets including the position locator, the slic-
ing metaphor, and the shape generator. Every operation is
performed in two-dimensional space. The classification re-
sults give the user a clear anatomical context for muscle de-
sign, such as the permitted size, location and orientation of
muscle volume as well as the spatial relationship with other
objects. The modeled muscle geometry is converted into a
list of fibers, and reformulated into a volume representation.
4. Intuitive Anatomy Classification
With the assistance of volume visualization, the user could
recognize the anatomical structures and design the intended
muscle volume. Therefore, it is highly desirable that both
tasks are performed following the intuitions of the user.
In our approach the user is required to only specify a list
of points on the rendered image to indicate schematically
meaningful regions. The visual information guides the user
to directly manipulate and justify the classification. Mean-
while, the classification results in turn provide effective hints
on optimizing transfer functions because the colors are de-
rived from the employed transfer function.
4.1. Region labeling in two-dimensional space
When a set of labeled points are drawn in the rendered im-
age, they are cast into the volume space along the view-
ing direction (Figure 2). To capture all potential regions,
densely distributed points are first generated along each ray,
together with their colors and opacities under the underlying
transfer function. We group the sampling points sequentially
along each ray based on their similarity in the RGB color
space, and choose several representative samples from each
grouped set. The voxels corresponding to those representa-
tive samples are considered as unlabeled points. Note that,
the colors of the labeled points are different from those of
the sampling points.
Figure 2: In the image plane, five points are labeled as three
classes. Other points are unlabeled.
4.2. Semi-supervised classification in the color space
We now have two sets of points, namely, the labeled points in
the rendered image, and the unlabeled sampling points in the
volume space. Our classification scheme is inspired by the
following assumption: one observed color is the composition
of the colors of its associated sampling points, and statisti-
cally tends to be similar to the ones that dominate the com-
position. As a consequence, we employ a semi-supervised
learning algorithm to classify the unlabeled sampling points
in RGB color space.
For the sake of brevity we describe our method with the
similar notations from [ZGL03]. By regarding each point as
a node, we construct a connected graph G = (V,E) where
V consists of n points, of which L = {1, ..., l} are the la-
beled points with labels y1, ...,yl, and U = {l + 1, ..., l+ u}
are the unlabeled points. In Figure 3 (a), five labeled points
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
889
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
are displayed in the first column, while the remaining ones
are unlabeled. Each labeled point is composed of the ones in
the same row.
(a) (b)
=
=
=
=
=
Figure 3: Illustration of our semi-supervised classifica-
tion algorithm. Various glyphs are used to encode different
classes.
To assign a label to each node in U , we compute an n× n
symmetric weight matrix W for the edges of G:
?i j = exp(?
3
?
d=1
(
x
d
i ? xdj
)2
) (1)
where xdi is the d-th color channel of the ith point xi. The
objective is to compute a real-valued function f : V ? on
G to satisfy the property that f (i) = fl (i)? yi on the labeled
data i= 1, ..., l, and to minimize a quadratic energy function:
E ( f ) = 1
2?i, j ?i j ( f (i)? f ( j))
2 (2)
The minimum energy function f ? = argmin f |L= fl E ( f ) is
harmonic in the sense that it is identical to fl on the labeled
point sets L and satisfies ? f = 0 on the unlabeled point set U .
? is the combinatorial Laplacian operator and can be repre-
sented in a matrix form ? = D?W, where D = diag(di) is
the diagonal matrix with entries di =? j wi j, and W =
[
wi j
]
is the weight matrix in Equation 2. We rewrite ? f = 0 as
f = P f , where P = D?1W.
By dividing the matrix W, D and P into four blocks along
the lth row and column, we have:
W =
[
Wll Wlu
Wul Wuu
]
(3)
With the denotation f =
[ fl
fu
]
where fu represents the
values on the unlabeled data points, the harmonic solution
? f = 0 is given by:
fu = (Duu?Wuu)?1 Wul fl = (I?Puu)?1 Pul fl (4)
where I is an u× u identity matrix.
Suppose that there are m regions {r1, r2, r3, ..., rm} speci-
fied by the user. fu gives a probability fui to each unknown
point. We determine its label (Figure 3 (b)) by applying a
threshold ? to fui:
xi ? r j i f | fui? j|< ? j ? 1,2,3, ...,m (5)
A typical choice for ? is 0.2. We ignore the points that
do not belong to any region. This guarantees that only the
points approximating the observed colors are labeled, yield-
ing a conservative classification result.
4.3. Statistical region merging
In the next step, all voxels are classified with a statistical
region merging algorithm [NN04] by using the identified
sampling points as the seeding points. Rather than using
solely the similarity of the scalar values as the merging cri-
teria, we use the scalar and gradient magnitude of voxels to
guide the region merging. The classified volume is then ren-
dered by assigning different colors to individual regions. The
user can justify the result and improve it by changing view-
points or transfer functions, and label additional points in
the image plane to trigger the modifications to the classifica-
tion. This process can be repeated until satisfying results are
achieved. For a 256×128×256 volume dataset and 800 un-
labeled points, our un-optimized implementation consumes
about 1.5 seconds to perform semi-supervised learning, and
5 seconds for statistical region merging. Therefore, the en-
tire anatomy classification could be accomplished in several
minutes, even with multiple iterations.
5. Modeling of the Skeletal Muscles
Before the muscle modeling, the user can check the classi-
fied anatomies to get a clear context. Similar to the classifi-
cation process, the modeling operations are fully carried out
in the two-dimensional space by leveraging the context built
from the anatomy classification. In the following sections,
we describe how a user can easily generate the shape, in-
ternal structures and the volume of a muscle model with a
group of convenient widgets.
5.1. Widgets for modeling the muscle geometry
A set of muscle geometry modeling widgets are designed,
including:
• The slicing metaphor A slicing metaphor is used to ad-
just the slicing plane to eliminate the occlusion, and as
a designing space in which the user specifies the muscle
shape. It could be translated, uniformly scaled or rotated
around its local axes (Figure 4 (a)). In our system, one
slicing plane is sufficient to generate a skeletal muscle.
• The shape generator and modifier The shape of a mus-
cle is described as a surface formed from a medial axis and
several contour curves produced from the user-specified
strokes. Guided by the display in the volume rendering
window, the user manipulates a slicing plane and draws
two strokes in the slicing plane to indicate the muscle con-
tour. Our system converts the strokes into B-spline curves
and highlights their controlling points whose positions
can be interactively altered. Then the B-spline curves are
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
890
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
rotated along a computed medial axis to produce multiple
contour lines, forming the geometry of a muscle (Figure 4
(b) and (c)).
• The position editor In addition to conventional rotat-
ing, scaling and translating operators, the modeled mus-
cle geometry can be arbitrarily located, added, deleted
and cloned. Figure 4 (d) shows the muscles with simple
cloning and modification operations.
(a) (b)
(c) (d)
Figure 4: Widgets used for modeling the muscle geometry.
(a) The slicing metaphor; (b) The shape generator in a slic-
ing plane; (c) The shape generator in a volume rendering
window; (d) The position editor.
All these widgets enable the user to explicitly determine
the muscle volume without a massive amount of efforts. A
huge benefit from the anatomy classification is its available
context. Specifically, we employ the following schemes to
optimize the modeling operations:
• Relationship The user can study the relationships among
anatomies by visualizing the classified results, e.g., the
one shown in Figure 1. A rough planning on how to place
the muscle volume could be formed.
• Location and size Typically, classified regions include
skin, bone, vessel, muscle, air and other unclassified ones.
Based on the locations of the skin and bone regions, the
user is allowed to interactively compute the axes of the
slicing planes, and estimate the bounding box of the un-
derlying muscle volume.
• Penetration Biologically correct muscle volumes should
be embedded in the classified muscle region. By assigning
a mask to each voxel, our system automatically prevents
the penetrations of the designed muscle into other regions
when specifying the controlling vertices of the B-spline
curves. Given a vertex sampled from the muscle contour
specified by the user, all voxels formed by rotating the
vertex along the medial axis are checked. If all of them
belong to the muscle region, the position of this vertex
is permitted. Otherwise, the user has to choose another
conservative position. Figure 5 illustrates an example of
preventing penetration.
(a) (b)
Figure 5: Designing fibers (a) without and (b) with prevent-
ing the penetration. In both cases, the red lines indicate pro-
hibited drawings.
Our experimental results demonstrate that these schemes
facilitate generating satisfying muscle volumes. More so-
phisticated and complicated contexts can be used for profes-
sional modeling users, as introduced in [BTS?05, TSB?05].
5.2. Modeling the muscle outlier shape
To model the shape of a skeletal muscle, we compute sev-
eral B-spline curves from the controlling points, and evenly
sample a collection of points on the curves. To find the me-
dial axis, we pair the sample points on two curves and com-
pute their midpoints. Then they are sequentially connected to
form the medial axis (Figure 6 (a)). To generate more con-
tours, we rotate the existing contours along the medial axis,
with which the scaling of the contour deviation from the me-
dial axis can be easily decided. In addition, we build a local
coordinate system of the muscle by orienting the axis to be
along the z-axis of the volume space (Figure 6 (b)).
Z
XY
(a) (b) (c) (d)
Figure 6: Generating the outlier shape and internal fibers of
a skeletal muscle.
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
891
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
5.3. Modeling the internal muscle structures
Generating the internal muscle structures is performed in
two steps. By assuming that the muscle cross-section is per-
pendicular to the z-axis of the local coordinate system, we
sequentially sample a list of points on the contour curves and
group them into a sequence of cross-sections. Subsequently
the boundary of each cross-section is generated (Figure 6
(c)). For the plane of each cross-section, we interpolate a set
of points inside the boundary formed by the contour curves.
Thereafter, a number of fibers are generated by connecting
all points along the medial axis (Figure 6 (d)). The set of the
generated fibers forms a fiber bundle, and represents a skele-
tal muscle. Our system also allows the user to interactively
or automatically choose the rear parts of a fiber as a tendon
component of a muscle, e.g., the white parts shown in the
final results.
5.4. Modeling of the muscle volume
We convert each fiber into a volumetric representation us-
ing the three-dimensional gaussian-weighted line voxeliza-
tion algorithm [WKZL04], and replace the corresponding
parts in the input volume. A mask is assigned to each voxel
to indicate its classification. Specifically, the tendon part of
each fiber is denoted with a different mask in the volume.
To allow for line-based illumination [Ban94], the direction
of each fiber is recorded, and replaces the per-voxel gradient
during volume illustration.
6. Results and Discussions
We applied the proposed approach to four volume datasets.
All experimental results were collected at a PC equipped
with an Intel Core 2 Duo E6600 2.4 GHz CPU, 3G host
memory and Nvidia Geforce GTX 280 graphics card. Ta-
ble 1 summarizes the experimental configuration, the user
time (UT) for the classification, the solving time (ST) for the
classification, and the user time (MT) for modeling muscles
in seconds for the results reported in this paper. The third
and fourth columns list the number of the sampling points
(#P) used for the color-space classification, and the number
of the modeled fiber bundles (#F).
Data #size #P #F UT ST MT
Feet 256×128×256 5000 10 450 6.5 3030
Hand 256×256×128 3000 17 360 4.4 5410
Knee 256×128×256 2500 4 260 6.5 1240
Abdomen 256×128×256 2400 - 650 7.5 -
Table 1: The time statistics in seconds for four datasets.
An unoptimized volume renderer was used to render the
results at the image resolution of 800× 800. The average
rendering performance is 5 fps. With the volume mask that
indicates the volume classification, varied shading or color
can be applied to different objects, e.g., the tendon part of
a fiber is rendered in white while the other parts are in red.
Expressive muscle illustration requires a high resolution of
the modeled volumetric fibers. In our approach, a fiber is
modeled with a volumetric line whose width is seven voxels.
Due to the limited volume resolution of the input volume
data, the fiber number in a fiber bundle might be low. We
upsample the volume datasets with higher resolutions, and
increase the number of generated fibers in each muscle. In
all examples listed in Table 1, the resolutions of the modeled
muscle volumes are 5123.
The anatomy classification in our approach is enabled by
a semi-supervised learning in the color space, while the ob-
served colors are determined by the employed transfer func-
tion. In the meantime, a transfer function can be used to
generate a volume classification. For each example, we have
tested a variety of transfer functions, and found that the ef-
ficiency of our approach is stable. Figure 7 demonstrates
that our approach can achieve better classifications than the
standard transfer function design. Even if there are certain
vague regions in the rendered image, our system still per-
forms well. This robustness is facilitated by the sufficiently
large sampling points in the volume space.
Figure 7: Top row: the classification results with a conven-
tional transfer function. The other pictures show six consec-
utive classification results with our approach. Each result is
associated with a specific user indication in the image plane.
Figures 8 and 9 show the volume modeling results for the
Hand and the Knee datasets. In each example, a hand-drawn
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
892
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
Figure 8: Top left: a hand-drawn illustration.(Image cour-
tesy of Zygote Media Group, www.3DScience.com); bottom
left: the modeled fiber bundles with our approach; right: a
volume illustration of the Hand dataset with the modeled
muscle. Please note the white tendon in the fibers.
illustration is shown. It is apparent that the modeled muscles
greatly enhance the depiction and the expressiveness of the
volume illustrations of both datasets, moving closer to the
hand-drawn illustrations than conventional volume rendered
images. The result of the Feet dataset is presented in Fig-
ure 10, where we compare a hand-drawn illustration and two
volume illustrations with and without the modeled muscle.
We conclude that our approach does improve the shape de-
piction by fusing additional anatomical information of some
volumetric muscle.
Figure 11 compares the classification results with a stan-
dard transfer function and our approach. Our approach effec-
tively separates all objects including the regions of a colon
and two kidneys, while the conventional transfer functions
can hardly fulfill this task.
7. Conclusions
We have described an easy-to-use system for modeling the
muscle volume with an intelligent two-dimensional inter-
face. One distinctive feature of our method is that the mod-
eling is context-aware, and the classification of anatomical
structures is performed in the color space. With our system,
the muscle volume can be easily built by means of a group
of convenient sketch-based volume modeling widgets, pro-
viding great convenience to the non-professional modeling
Figure 9: Top left: a hand-drawn illustra-
tion.(Image courtesy of Medical Multimedia Group,
www.medicalmultimediagroup.com); bottom left: the mod-
eled fiber bundles with our approach; right: a volume
illustration of the Knee dataset and the modeled muscle.
Figure 10: Top left: a hand-drawn illustra-
tion.(Image courtesy of Medical Multimedia Group,
www.medicalmultimediagroup.com); bottom left: a conven-
tional volume illustration; right: a volume illustration with
the modeled muscle.
users such as the medical illustrators. In addition to be a sim-
ple yet efficient muscle modeling tool, the presented work is
useful in muscle rendering such as medical illustration and
anatomy simulation.
In our currrent implementation, the medial axis of target
muscle is estimated by the user and then coincided with the
slicing plane. This task would require more efforts when the
geometry of the target muscle is non-trivial. We plan to ex-
tract related information such as the bounding box and the
orientation of fibers from the input volume data to facili-
tate locating the medial axis. In addition, since the surface
geometry of the target muscle is formed by rotating the con-
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
893
Z. Yan & W. Chen & A. Lu & D. Ebert / Context-aware Volume Modeling of Skeletal Muscles
Figure 11: Classification results for the Abdomen dataset
with a well-tuned transfer function (left) and with our ap-
proach (right). The region (denoted by a red circle) of a
colon and two kidneys can not be separated with the transfer
function while ours can.
tours, the types of muscle shapes are limited. An interesting
future work would be to utilize more flexible muscle mod-
eling toolkits like shape deformation, finite element models
and kinetic animation modeling. We also plan to explore an
interactive approach to generate real-world muscle volumes
from measured diffusion tensor images (DTI) datasets, and
integrate them into other volume data for expressive infor-
mation fusion.
8. Acknowledgements
This work has been funded by Natural Science Founda-
tions of China (No. 60873123), the US DOE DE-FG02-
06ER25733 and NSF 0633150, the US NSF under Grant
0328984 and by the US Department of Homeland Security
Regional Visualization and Analytics Center (RVAC) Center
of Excellence.
References
[Ban94] BANKS D. C.: Illumination in diverse codimensions. In
Proceedings of ACM SIGGRAPH (1994), pp. 327–334.
[BG05] BRUCKNER S., GRÖLLER M. E.: VolumeShop: An in-
teractive system for direct volume illustration. In Proceedings of
IEEE Visualization (October 2005), pp. 671–678.
[BGKG06] BRUCKNER S., GRIMM S., KANITSAR A.,
GRÖLLER M. E.: Illustrative context-preserving explo-
ration of volume data. IEEE Transactions on Visualization and
Computer Graphics 12, 6 (2006), 1559–1569.
[BJ01] BOYKOV Y. Y., JOLLY M.-P.: Interactive graph cuts for
optimal boundary and region segmentation of objects in N-D im-
ages. In Proceedings of International Conference on Computer
Vision (2001), vol. 1, pp. 105–124.
[BKW08] BÜRGER K., KRÜGER J., WESTERMANN R.: Direct
volume editing. IEEE Transactions on Visualization and Com-
puter Graphics 14, 6 (2008), 1388–1395.
[BTS?05] BLEMKER S., TERAN J., SIFAKIS E., FEDKIW R.,
DELP S.: Fast 3D muscle simulations using a new quasistatic
invertible finite-element algorithm. In 10th International Sympo-
sium on Computer Simulation in Biomechanics (July 2005).
[CCI?07] CHEN M., CORREA C., ISLAM S., JONES M., SHEN
P.-Y., SILVER D., WALTON S., P.J.WILLIS: Manipulating, de-
forming and animating sampled object representations. Com-
puter Graphics Forum 26, 4 (August 2007), 824–852.
[CSC06] CORREA C., SILVER D., CHEN M.: Feature-aligned
volume manipulation for illustration and visualization. IEEE
Transactions on Visualization and Computer Graphics 12, 5
(2006), 1069–1076.
[FRB07] FRUCCI M., RAMELLA G., BAJA G.: Using resolution
pyramids for watershed image segmentation. Image Vision Com-
puting 25, 6 (2007), 1021–1031.
[KHS01] KÄHLER K., HABER J., SEIDEL H.-P.: Geometry-
based muscle modeling for facial animation. In Proceedings of
Graphics Interface (2001), pp. 37–46.
[MTB03] MCGUFFIN M., TANCAU L., BALAKRISHNAN R.: Us-
ing deformations for browsing volumetric data. In Proceedings
of IEEE Visualization (October 2003), pp. 401–408.
[NN04] NOCK R., NIELSEN F.: Statistical region merging. IEEE
Transactions on Pattern Analysis and Machine Intelligence 26,
11 (2004), 1452–1458.
[ONI05] OWADA S., NIELSEN F., IGARASHI T.: Volume catcher.
In Proceedings of ACM I3D (2005), pp. 111–116.
[PLB?01] PFISTER H., LORENSEN B., BAJAJ C., KINDLMANN
G., SCHROEDER W., AVILA L. S., MARTIN K., MACHIRAJU
R., LEE J.: The transfer function bake-off. IEEE Computer
Graphics and Applications 21, 3 (2001), 16–22.
[RLC04] ROMMELSE J. R., LIN H. X., CHAN T. F.: Efficient
active contour and K-means algorithms in image segmentation.
Scientific Programming 12, 2 (2004), 101–120.
[SPCM97] SCHEEPERS F., PARENT R. E., CARLSON W. E.,
MAY S. F.: Anatomy-based modeling of the human muscula-
ture. In Proceedings of ACM SIGGRAPH (1997), pp. 163–172.
[SS04] SINGH V., SILVER D.: Interactive volume manipulation
with selective rendering for improved visualization. In Proceed-
ings of IEEE Symposium on Volume Visualization and Graphics
(October 2004), pp. 95–102.
[STS90] SOBOTTA J., TAYLOR A. N., STAUBESAND J.: Sobotta
Atlas of human anatomy. Urban and Schwarzenberg, 1990.
[SWY99] SHAREEF N., WANG D. L., YAGEL R.: Segmentation
of medical images using LEGION. IEEE Transactions on Medi-
cal Imaging 18, 1 (1999), 74–91.
[TLM05] TZENG F.-Y., LUM E. B., MA K.-L.: An intelligent
system approach to higher-dimensional classification of volume
data. IEEE Transactions on Visualization and Computer Graph-
ics 11, 3 (2005), 273–284.
[TSB?05] TERAN J., SIFAKIS E., BLEMKER S., HING V. N. T.,
LAU C., FEDKIW R.: Creating and simulating skeletal muscle
from the visible human data set. IEEE Transactions on Visual-
ization and Computer Graphics 11, 3 (2005), 317–328.
[WKZL04] WENGER A., KEEFE D., ZHANG S., LAIDLAW
D. H.: Interactive volume rendering of thin thread structures
within multivalued scientific datasets. IEEE Transactions on Vi-
sualization and Computer Graphics 10, 6 (2004), 664–672.
[YZNC05] YUAN X., ZHANG N., NGUYEN M. X., CHEN B.:
Volume cutout. The Visual Computer 21, 8–10 (2005), 745–754.
[ZBS01] ZHANG Y., BRADY M., SMITH S.: Segmentation of
brain MR images through a hidden markov random field model
and the expectation-maximization algorithm. IEEE Transactions
on Medical Imaging 20, 1 (2001), 45–57.
[ZGL03] ZHU X., GHAHRAMANI Z., LAFFERTY J.: Semi-
supervised learning using gaussian fields and harmonic func-
tions. In Proceedings of ICML (2003), pp. 912–919.
c© 2009 The Author(s)
Journal compilation c© 2009 The Eurographics Association and Blackwell Publishing Ltd.
894

